{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MBA Aula 07 Lista de Exercicios.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flekT6GFDN6m"
      },
      "source": [
        "# <span style=\"color:blue\">MBA em Ciência de Dados</span>\n",
        "# <span style=\"color:blue\">Análise de Dados com Base em Processamento Massivo em Paralelo</span>\n",
        "\n",
        "## <span style=\"color:blue\">Aula 07: Consultas OLAP usando Spark SQL</span>\n",
        "## <span style=\"color:blue\">Apache Spark SQL</span>\n",
        "\n",
        "**Material Produzido por:**<br>\n",
        ">**Profa. Dra. Cristina Dutra de Aguiar**<br>\n",
        "\n",
        "**CEMEAI - ICMC/USP São Carlos**\n",
        "\n",
        "Este *notebook* contém exercícios classificados como essenciais e complementares. A indicação da classificação de cada exercício é feita junto de sua definição. Os exercícios estão espalhados ao longo do texto. Por favor, procurem por EXERCÍCIO para encontrar a especificação dos exercícios e as suas respectivas respostas. Também é possível localizar os exercícios utilizando o menu de navegação. Por completude, o *notebook* possui todas as descrições apresentadas na parte prática da Aula 07. Recomenda-se fortemente que a lista de exercícios seja respondida antes de se consultar as respostas dos exercícios.\n",
        "\n",
        "**IMPORTANTE: O uso do *framework* Spark requer diversas configurações no ambiente de desenvolvimento para executar o *notebook*. Dado que tal complexidade foge do escopo de nossa disciplina, recomenda-se que o *notebook* seja executado na plataforma de desenvolvimento COLAB. O uso do COLAB  proporciona um ambiente de desenvolvimento pré-configurado e remove a complexidade de instalação e configuração de pacotes e *frameworks* que são utilizados na disciplina.** \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR1B90NXB9Vo"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8OQ0vEvCB_k"
      },
      "source": [
        "EXECUTADO NO COLAB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3o3dN_WLQcyD"
      },
      "source": [
        "#1 Otimizador de Consultas Catalyst\n",
        "\n",
        "O componente mais importante do Spark SQL é o seu otimizador de consultas, chamado Catalyst. Catalyst é baseado em construtores de programação funcional e é implementado na linguagem de programação Scala. Sua implementação tem dois propósitos principais. O primeiro é permitir que novas técnicas de otimização e novas características possam ser facilmente adicionadas ao Spark SQL. O segundo propósito consiste em possibilitar que desenvolvedores externos estendam o otimizador de consultas, por exemplo, adicionando novas regras de otimização e provendo suporte para novos tipos de dados, dentre outros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7rEE-45DhOW"
      },
      "source": [
        "## 1.1 Plano de Consulta\n",
        "\n",
        "Dada uma consulta em alto nível, existem diferentes estratégias de execução (ou seja, planos de consulta) alternativas para se processar essa consulta, principalmente se ela for complexa. A otimização de consultas consiste no processo de gerar e selecionar o plano de consulta mais eficiente dentre as diversas possibilidades disponíveis, ou seja, consiste no processo de selecionar o plano de consulta de menor custo. \n",
        "\n",
        "De fato, a quantidade de possíveis planos de consulta que podem ser gerados para processar uma consulta pode ser muito grande. Assim, no processamento de uma consulta, nem todos os planos possíveis são gerados e analisados, uma vez que o tempo gasto nesta atividade seria provavelmente excessivo, talvez superando o tempo de responder à consulta por meio de uma busca sequencial. Heurísticas são usualmente empregadas para diminuir o espaço de busca. \n",
        "\n",
        "Portanto, o otimizador de consultas em geral não produz uma solução que é a ótima ou de menor custo frente a todas as possibilidades existentes, mas produz uma solução que é a melhor frente a algumas dessas possibilidades. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KT2g66RkPd6d"
      },
      "source": [
        "\n",
        "##1.2 Técnicas de Otimização\n",
        "\n",
        "Duas técnicas amplamente utilizadas pelo otimizador de consultas são descritas a seguir.\n",
        "\n",
        "- Otimização baseada em regras. O otimizador de consultas baseado em regras tem por objetivo gerar apenas um subconjunto de planos a serem analisados, usado como base heurísticas. Cada plano gerado pelo otimizador de consultas baseado em regras consiste de uma expressão algébrica que determina a ordem na qual as operações deve ser executadas, de forma que todos os planos para uma determinada consulta sejam equivalentes.\n",
        "\n",
        "- Otimização baseada em custo. O otimizador de consultas baseado em custo identifica, para cada plano gerado, o custo para processar a consulta, e seleciona o plano de menor custo. Isso depende de diversos fatores, tais como quais as operações algébricas que encontram-se efetivamente implementadas por meio de algoritmos disponilizados e os índices disponíveis para processar a consulta. \n",
        "\n",
        "Catalyst realiza otimização de consultas baseada em regras e otimização de consultas baseada em custo para transformar uma consulta escrita em SQL em códigos que executam sobre RDDs e utilizam os princípios do modelo MapReduce e do sistema de arquivos distribuídos HDFS.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGeh8KdXwVCQ"
      },
      "source": [
        "# 2 Constelação de Fatos da BI Solutions\n",
        "\n",
        "A aplicação de *data warehousing* da BI Solutions utiliza como base uma constelação de fatos, conforme descrita a seguir.\n",
        "\n",
        "**Tabelas de dimensão**\n",
        "\n",
        "- data (dataPK, dataCompleta, dataDia, dataMes, dataBimestre, dataTrimestre, dataSemestre, dataAno)\n",
        "- funcionario (funcPK, funcMatricula, funcNome, funcSexo, funcDataNascimento, funcDiaNascimento, funcMesNascimento, funcAnoNascimento, funcCidade, funcEstadoNome, funcEstadoSigla, funcRegiaoNome, funcRegiaoSigla, funcPaisNome, funcPaisSigla)\n",
        "- equipe (equipePK, equipeNome, filialNome, filialCidade, filialEstadoNome, filialEstadoSigla, filialRegiaoNome, filialRegiaoSigla, filialPaisNome, filialPaisSigla)\n",
        "- cargo (cargoPK, cargoNome, cargoRegimeTrabalho, cargoEscolaridadeMinima, cargoNivel)\n",
        "- cliente (clientePK, clienteNomeFantasia, clienteSetor, clienteCidade, clienteEstadoNome, clienteEstadoSigla, clienteRegiaoNome, clienteRegiaoSigla, clientePaisNome, clientePaisSigla)\n",
        "\n",
        "**Tabelas de fatos**\n",
        "- pagamento (dataPK, funcPK, equipePK, cargoPK, salario, quantidadeLancamentos)\n",
        "- negociacao (dataPK, equipePK, clientePK, receita, quantidadeNegociacoes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCCNC64AzBG0"
      },
      "source": [
        "## 2.1 Baixando o Módulo wget\n",
        "\n",
        "Para baixar os dados referentes ao esquema relacional da constelação de fatos da BI Solutions, é utilizado o módulo  **wget**. O comando a seguir realiza a instalação desse módulo. <br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e0Eao1K0EYG"
      },
      "source": [
        "#instalando o módulo wget\n",
        "%%capture\n",
        "!pip install -q wget\n",
        "#criando pasta para salvar as bases de dados\n",
        "!mkdir data"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j56pVJ2hZ2i5"
      },
      "source": [
        "## 2.2 Obtenção dos Dados das Tabelas de Dimensão\n",
        "\n",
        "Os comandos a seguir baixam os dados que povoam as tabelas de dimensão. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46QzTpLJwfkW",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0748afe8-ebaf-45cc-c665-3f5253178cc4"
      },
      "source": [
        "#baixando os dados das tabelas de dimensão\n",
        "import wget\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/GuiMuzziUSP/Data_Mart_BI_Solutions/main/data.csv\"\n",
        "wget.download(url, \"data/data.csv\")\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/GuiMuzziUSP/Data_Mart_BI_Solutions/main/funcionario.csv\"\n",
        "wget.download(url, \"data/funcionario.csv\")\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/GuiMuzziUSP/Data_Mart_BI_Solutions/main/equipe.csv\"\n",
        "wget.download(url, \"data/equipe.csv\")\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/GuiMuzziUSP/Data_Mart_BI_Solutions/main/cargo.csv\"\n",
        "wget.download(url, \"data/cargo.csv\")\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/GuiMuzziUSP/Data_Mart_BI_Solutions/main/cliente.csv\"\n",
        "wget.download(url, \"data/cliente.csv\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'data/cliente.csv'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0o-dC7feszRc"
      },
      "source": [
        "## 2.3 Obtenção dos Dados Tabelas de Fatos\n",
        "\n",
        "Os comandos a seguir baixam os dados que povoam as tabelas de fatos. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWM-CUFgBl_8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "31e0e555-0434-47cc-a6dc-ef08c56fe272"
      },
      "source": [
        "#baixando os dados das tabelas de fatos\n",
        "url = \"https://raw.githubusercontent.com/GuiMuzziUSP/Data_Mart_BI_Solutions/main/pagamento.csv\"\n",
        "wget.download(url, \"data/pagamento.csv\")\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/GuiMuzziUSP/Data_Mart_BI_Solutions/main/negociacao.csv\"\n",
        "wget.download(url, \"data/negociacao.csv\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'data/negociacao.csv'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO16-7-jOioq"
      },
      "source": [
        "# 3 Apache Spark Cluster"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVEgY9qKflBV"
      },
      "source": [
        "## 3.1 Instalação\n",
        "\n",
        "Neste *notebook* é criado um *cluster* Spark composto apenas por um **nó mestre**. Ou seja, o *cluster* não possui um ou mais **nós de trabalho** e o **gerenciador de cluster**. Nessa configuração, as tarefas (*tasks*) são realizadas no próprio *driver* localizado no **nó mestre**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaM-OnIjgLS2"
      },
      "source": [
        "Para que o cluster possa ser criado, primeiramente é instalado o Java Runtime Environment (JRE) versão 8. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXls3bfoglKW"
      },
      "source": [
        "#instalando Java Runtime Environment (JRE) versão 8\n",
        "%%capture\n",
        "!apt-get remove openjdk*\n",
        "!apt-get update --fix-missing\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BQzZfDYhb4j"
      },
      "source": [
        "Na sequência, é feito o *download* do Apache Spark versão 3.0.0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a_Yv59zg3gm"
      },
      "source": [
        "#baixando Apache Spark versão 3.0.0\n",
        "%%capture\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop2.7.tgz\n",
        "!tar xf spark-3.0.0-bin-hadoop2.7.tgz && rm spark-3.0.0-bin-hadoop2.7.tgz"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RETWX6wqhkLf"
      },
      "source": [
        "Na sequência, são configuradas as variáveis de ambiente JAVA_HOME e SPARK_HOME. Isto permite que tanto o Java quanto o Spark possam ser encontrados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZpR7NwOh2EB"
      },
      "source": [
        "import os\n",
        "#configurando a variável de ambiente JAVA_HOME\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "#configurando a variável de ambiente SPARK_HOME\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop2.7\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ql0z7Ro1iHQb"
      },
      "source": [
        "Por fim, são instalados dois pacotes da linguagem de programação Python, cujas funcionalidades são descritas a seguir.\n",
        "\n",
        "> **Pacote findspark:** Usado para ler a variável de ambiente SPARK_HOME e armazenar seu valor na variável dinâmica de ambiente PYTHONPATH. Como resultado, Python pode encontrar a instalação do Spark. \n",
        "\n",
        "> **Pacote pyspark:** PySpark é a API do Python para Spark. Ela possibilita o uso de Python, considerando que o *framework* Apache Spark encontra-se desenvolvido na linguagem de programação Scala. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oSYOwKljPf5"
      },
      "source": [
        "%%capture\n",
        "#instalando o pacote findspark\n",
        "!pip install -q findspark==1.4.2\n",
        "#instalando o pacote pyspark\n",
        "!pip install -q pyspark==3.0.0"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAaLyjPzmIwZ"
      },
      "source": [
        "## 3.2 Conexão\n",
        "\n",
        "PySpark não é adicionado ao *sys.path* por padrão. Isso significa que não é possível importá-lo, pois o interpretador da linguagem Python não sabe onde encontrá-lo. \n",
        "\n",
        "Para resolver esse aspecto, é necessário instalar o módulo `findspark`. Esse módulo mostra onde PySpark está localizado. Os comandos a seguir têm essa finalidade.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zm1pBTEmjp4"
      },
      "source": [
        "#importando o módulo findspark\n",
        "import findspark\n",
        "#carregando a variávels SPARK_HOME na variável dinâmica PYTHONPATH\n",
        "findspark.init()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDqfefF7YUab"
      },
      "source": [
        "Depois de configurados os pacotes e módulos e inicializadas as variáveis de ambiente, é possível iniciar o uso do Spark na aplicação de `data warehousing`. Para tanto, é necessário importar o comando `SparkSession` do módulo `pyspark.sql`. São utilizados os seguintes conceitos: <br>\n",
        "\n",
        "- `SparkSession`: permite a criação de `DataFrames`. Como resultado, as tabelas relacionais podem ser manipuladas por meio de `DataFrames` e é possível realizar consultas OLAP por meio de comandos SQL. <br>\n",
        "- `builder`: cria uma instância de SparkSession. <br>\n",
        "- `appName`: define um nome para a aplicação, o qual pode ser visto na interface de usuário web do Spark. <br> \n",
        "- `master`: define onde está o nó mestre do *cluster*. Como a aplicação é executada localmente e não em um *cluster*, indica-se isso pela *string* `local` seguida do parâmetro `[*]`. Ou seja, define-se que apenas núcleos locais são utilizados. \n",
        "- `getOrCreate`: cria uma SparkSession. Caso ela já exista, retorna a instância existente. \n",
        "\n",
        "\n",
        "**Observação**: A lista completa de todos os parâmetros que podem ser utilizados na inicialização do *cluster* pode ser encontrada neste [link](https://spark.apache.org/docs/latest/spark-standalone.html#cluster-launch-scripts)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TxljJ_cwBCy"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"pyspark-notebook\").master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qL9SiR_pQE2"
      },
      "source": [
        "# 4 Preparação dos Dados\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtUGn-uyBJWY"
      },
      "source": [
        "## 4.1 Geração dos DataFrames\n",
        "\n",
        "Para a leitura dos dados dos arquivos .csv, é utilizado o método `spark.read.csv`. Seus parâmetros são:\n",
        "\n",
        "\n",
        "- `path`: endereço do arquivo que é lido.\n",
        "- `header`: indica se o arquivo possui um cabeçalho.\n",
        "- `sep`: especifica o caractere que separa os campos do arquivo.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "FNR-3dV6oYk4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2624523-52b4-4042-d701-ffd933c992d2"
      },
      "source": [
        "#criando e exibindo o DataFrame para a tabela de dimensão cargo\n",
        "cargo = spark.read.csv(path=\"data/cargo.csv\", header=True, sep=\",\")\n",
        "cargo.show(5)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+-------------------+--------------------+-----------------------+----------+\n",
            "|cargoPK|           cargoNome|cargoRegimeTrabalho|cargoJornadaTrabalho|cargoEscolaridadeMinima|cargoNivel|\n",
            "+-------+--------------------+-------------------+--------------------+-----------------------+----------+\n",
            "|      1|PROGRAMADOR DE SI...|         TEMPORARIO|                 20H|                  MEDIO|    JUNIOR|\n",
            "|      2|PROGRAMADOR DE SI...|         TEMPORARIO|                 20H|               SUPERIOR|     PLENO|\n",
            "|      3|PROGRAMADOR DE SI...|         TEMPORARIO|                 20H|                    POS|    SENIOR|\n",
            "|      4|PROGRAMADOR DE SI...|         TEMPORARIO|                 40H|                  MEDIO|    JUNIOR|\n",
            "|      5|PROGRAMADOR DE SI...|         TEMPORARIO|                 40H|               SUPERIOR|     PLENO|\n",
            "+-------+--------------------+-------------------+--------------------+-----------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPCF-SyBtuPW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f44e5de-4055-481e-f4a3-9f7b7d1cb1f6"
      },
      "source": [
        "#criando e exibindo o DataFrame para a tabela de dimensão cliente\n",
        "cliente = spark.read.csv(path=\"data/cliente.csv\", header=True, sep=\",\")\n",
        "cliente.show(5)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------------------+-------------------+-------------+-----------------+------------------+-----------------+------------------+---------------+----------------+\n",
            "|clientePK|clienteNomeFantasia|       clienteSetor|clienteCidade|clienteEstadoNome|clienteEstadoSigla|clienteRegiaoNome|clienteRegiaoSigla|clientePaisNome|clientePaisSigla|\n",
            "+---------+-------------------+-------------------+-------------+-----------------+------------------+-----------------+------------------+---------------+----------------+\n",
            "|        1|           VIA FOOD|BEBIDAS E ALIMENTOS|    SAO PAULO|        SAO PAULO|                SP|          SUDESTE|                SE|         BRASIL|              BR|\n",
            "|        2|          VIA PIZZA|BEBIDAS E ALIMENTOS|    SAO PAULO|        SAO PAULO|                SP|          SUDESTE|                SE|         BRASIL|              BR|\n",
            "|        3|           VIA JAPA|BEBIDAS E ALIMENTOS|    SAO PAULO|        SAO PAULO|                SP|          SUDESTE|                SE|         BRASIL|              BR|\n",
            "|        4|            VIA VEG|BEBIDAS E ALIMENTOS|    SAO PAULO|        SAO PAULO|                SP|          SUDESTE|                SE|         BRASIL|              BR|\n",
            "|        5|          VIA DRINK|BEBIDAS E ALIMENTOS|   SAO CARLOS|        SAO PAULO|                SP|          SUDESTE|                SE|         BRASIL|              BR|\n",
            "+---------+-------------------+-------------------+-------------+-----------------+------------------+-----------------+------------------+---------------+----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3p9dLUKts73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d795b3d7-38ff-4b90-cc94-0f312dd8ab9f"
      },
      "source": [
        "#criando e exibindo o DataFrame para a tabela de dimensão data\n",
        "data = spark.read.csv(path=\"data/data.csv\", header=True, sep=\",\") \n",
        "data.show(5)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------------+-------+-------+------------+-------------+------------+-------+\n",
            "|dataPK|dataCompleta|dataDia|dataMes|dataBimestre|dataTrimestre|dataSemestre|dataAno|\n",
            "+------+------------+-------+-------+------------+-------------+------------+-------+\n",
            "|     1|    1/1/2016|      1|      1|           1|            1|           1|   2016|\n",
            "|     2|    2/1/2016|      2|      1|           1|            1|           1|   2016|\n",
            "|     3|    3/1/2016|      3|      1|           1|            1|           1|   2016|\n",
            "|     4|    4/1/2016|      4|      1|           1|            1|           1|   2016|\n",
            "|     5|    5/1/2016|      5|      1|           1|            1|           1|   2016|\n",
            "+------+------------+-------+-------+------------+-------------+------------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Obef8NfyttuJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5539e28-74ae-49bd-befc-17d4abee9281"
      },
      "source": [
        "#criando e exibindo o DataFrame para a tabela de dimensão equipe\n",
        "equipe = spark.read.csv(path=\"data/equipe.csv\", header=True, sep=\",\")\n",
        "equipe.show(5)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------------+--------------------+--------------+------------------+-----------------+----------------+-----------------+--------------+---------------+\n",
            "|equipePK|   equipeNome|          filialNome|  filialCidade|  filialEstadoNome|filialEstadoSigla|filialRegiaoNome|filialRegiaoSigla|filialPaisNome|filialPaisSigla|\n",
            "+--------+-------------+--------------------+--------------+------------------+-----------------+----------------+-----------------+--------------+---------------+\n",
            "|       1|APP - DESKTOP|SAO PAULO - AV. P...|     SAO PAULO|         SAO PAULO|               SP|         SUDESTE|               SE|        BRASIL|             BR|\n",
            "|       2|APP - DESKTOP|RIO DE JANEIRO - ...|RIO DE JANEIRO|    RIO DE JANEIRO|               RJ|         SUDESTE|               SE|        BRASIL|             BR|\n",
            "|       3|          WEB|SAO PAULO - AV. P...|     SAO PAULO|         SAO PAULO|               SP|         SUDESTE|               SE|        BRASIL|             BR|\n",
            "|       4|          WEB|RIO DE JANEIRO - ...|RIO DE JANEIRO|    RIO DE JANEIRO|               RJ|         SUDESTE|               SE|        BRASIL|             BR|\n",
            "|       5|          WEB|CAMPO GRANDE - CE...|  CAMPO GRANDE|MATO GROSSO DO SUL|               MS|    CENTRO-OESTE|               CO|        BRASIL|             BR|\n",
            "+--------+-------------+--------------------+--------------+------------------+-----------------+----------------+-----------------+--------------+---------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsF4rcS7Zp4O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdd7f523-0506-4737-9d9e-641a1781f032"
      },
      "source": [
        "#criando e exibindo o DataFrame para a tabela de fatos funcionario\n",
        "funcionario = spark.read.csv(path=\"data/funcionario.csv\", header=True, sep=\",\")\n",
        "funcionario.show(5)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------+-------------+--------+------------------+-----------------+-----------------+-----------------+-----------+--------------+---------------+--------------+---------------+------------+-------------+\n",
            "|funcPK|funcMatricula|     funcNome|funcSexo|funcDataNascimento|funcDiaNascimento|funcMesNascimento|funcAnoNascimento| funcCidade|funcEstadoNome|funcEstadoSigla|funcRegiaoNome|funcRegiaoSigla|funcPaisNome|funcPaisSigla|\n",
            "+------+-------------+-------------+--------+------------------+-----------------+-----------------+-----------------+-----------+--------------+---------------+--------------+---------------+------------+-------------+\n",
            "|     1|          M-1|ALINE ALMEIDA|       F|          1/1/1990|                1|                1|             1990|  SAO PAULO|     SAO PAULO|             SP|       SUDESTE|             SE|      BRASIL|           BR|\n",
            "|     2|          M-2|   ARAO ALVES|       M|          2/2/1990|                2|                2|             1990|   CAMPINAS|     SAO PAULO|             SP|       SUDESTE|             SE|      BRASIL|           BR|\n",
            "|     3|          M-3| ARON ANDRADE|       M|          3/3/1990|                3|                3|             1990|     SANTOS|     SAO PAULO|             SP|       SUDESTE|             SE|      BRASIL|           BR|\n",
            "|     4|          M-4|  ADA BARBOSA|       F|          4/4/1990|                4|                4|             1990|SANTO ANDRE|     SAO PAULO|             SP|       SUDESTE|             SE|      BRASIL|           BR|\n",
            "|     5|          M-5|ABADE BATISTA|       M|          5/5/1990|                5|                5|             1990| PIRACICABA|     SAO PAULO|             SP|       SUDESTE|             SE|      BRASIL|           BR|\n",
            "+------+-------------+-------------+--------+------------------+-----------------+-----------------+-----------------+-----------+--------------+---------------+--------------+---------------+------------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4aZ0M6OZvg2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c2537f6-6c8f-4600-f79c-59b78230b9c1"
      },
      "source": [
        "#criando e exibindo o DataFrame para a tabela de fatos negociacao\n",
        "negociacao = spark.read.csv(path=\"data/negociacao.csv\", header=True, sep=\",\")\n",
        "negociacao.show(5)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------+------+--------+---------------------+\n",
            "|equipePK|clientePK|dataPK| receita|quantidadeNegociacoes|\n",
            "+--------+---------+------+--------+---------------------+\n",
            "|       2|        9|    22|11564.75|                    1|\n",
            "|       2|       24|    11| 17990.5|                    1|\n",
            "|       2|       28|    21| 16335.9|                    1|\n",
            "|       1|       30|    23| 8495.55|                    1|\n",
            "|       2|       43|    30|24748.75|                    1|\n",
            "+--------+---------+------+--------+---------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzVUaFptodHJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec8482de-6c84-4420-dd92-30ffeb626e4b"
      },
      "source": [
        "#criando e exibindo o DataFrame para a tabela de fatos pagamento\n",
        "pagamento = spark.read.csv(path=\"data/pagamento.csv\", header=True, sep=\",\")\n",
        "pagamento.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+------+-------+--------+---------------------+\n",
            "|funcPK|equipePK|dataPK|cargoPK| salario|quantidadeLancamentos|\n",
            "+------+--------+------+-------+--------+---------------------+\n",
            "|   147|       2|     5|     64| 1559.94|                    1|\n",
            "|   124|       2|     5|    329| 8102.77|                    1|\n",
            "|   175|       1|     5|    328| 2532.51|                    1|\n",
            "|   171|       1|     5|    245|  7882.7|                    1|\n",
            "|   148|       2|     5|     65| 4404.59|                    1|\n",
            "|     5|       2|     5|    112| 2226.66|                    1|\n",
            "|   128|       1|     5|    341| 6157.04|                    1|\n",
            "|    82|       2|     5|     43| 1585.51|                    1|\n",
            "|    28|       1|     5|    253| 1594.02|                    1|\n",
            "|    46|       1|     5|    390| 9880.16|                    1|\n",
            "|    91|       2|     5|    233|10931.47|                    1|\n",
            "|   176|       2|     5|    241| 2005.49|                    1|\n",
            "|   172|       1|     5|    351|14218.28|                    1|\n",
            "|   155|       1|     5|    121| 2002.57|                    1|\n",
            "|    19|       2|     5|    223| 1778.26|                    1|\n",
            "|    94|       1|     5|    394|  2505.1|                    1|\n",
            "|    26|       2|     5|    350| 9162.46|                    1|\n",
            "|    55|       2|     5|    313| 3215.53|                    1|\n",
            "|    29|       1|     5|     62| 4128.44|                    1|\n",
            "|   181|       1|     5|    249|11082.75|                    1|\n",
            "+------+--------+------+-------+--------+---------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09knZQIwO03y"
      },
      "source": [
        "## 4.2 Criação de Visões Temporárias\n",
        "\n",
        "Para que seja possível executar consultas SQL usando Spark SQL, é necessário criar visões temporárias. Uma visão temporária é uma forma na qual um DataFrame pode ser consultado como se fosse uma tabela.\n",
        "\n",
        "Para tanto, deve ser utilizado o método  `createOrReplaceTempView` e deve ser passado como parâmetro uma *string* que é o nome da tabela que é criada a partir do DataFrame.  Os comandos a seguir criam uma visão temporária para cada DataFrame da aplicação de *data warehousing*. \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nB4dFUqHoiaW"
      },
      "source": [
        "#criando as visões temporárias para as tabelas de dimensão\n",
        "cargo.createOrReplaceTempView(\"cargo\")\n",
        "cliente.createOrReplaceTempView(\"cliente\")\n",
        "data.createOrReplaceTempView(\"data\")\n",
        "equipe.createOrReplaceTempView(\"equipe\")\n",
        "funcionario.createOrReplaceTempView(\"funcionario\")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PQgcY3honGm"
      },
      "source": [
        "#criando a visão temporária para as tabelas de fatos\n",
        "negociacao.createOrReplaceTempView(\"negociacao\")\n",
        "pagamento.createOrReplaceTempView(\"pagamento\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ss0pmgplPAL3"
      },
      "source": [
        "# 5 Execução de Consultas com Foco nas Operações OLAP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MABYjSYf7L4g"
      },
      "source": [
        "## 5.1 Operação Slice and Dice \n",
        "\n",
        "**Definição**: Restringe os dados sendo analisados a um subconjunto desses dados.\n",
        "\n",
        "- Slice: corte para um valor fixo, diminuindo a dimensionalidade do cubo.\n",
        "- Dice: seleção de faixas de valores.\n",
        "\n",
        "**Exemplo de consulta**: Qual a quantidade de pagamentos realizados no mês de setembro de 2020?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGMSoyQRoqnz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "922b214b-b62c-439c-c52c-1aecda26b40b"
      },
      "source": [
        "query = \"\"\"\n",
        "SELECT CAST(SUM(quantidadeLancamentos) AS INTEGER) AS `Quantidade de Lançamentos`\n",
        "FROM data JOIN pagamento ON (data.dataPK = pagamento.dataPK) \n",
        "WHERE dataAno = 2020 \n",
        "      AND dataMes = 9\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------+\n",
            "|Quantidade de Lançamentos|\n",
            "+-------------------------+\n",
            "|                      200|\n",
            "+-------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjeYu20EoUyO"
      },
      "source": [
        "### **EXERCÍCIO 1 (Essencial)** \n",
        "\n",
        "Qual o total de negociações realizadas nos meses de Abril, Maio e Junho de 2016? Renomeie o resultado final como \"Quantidade de Negociações\". \n",
        "\n",
        "Dica: utilize a medida numérica `quantidadeNegociacoes` presente na tabela `negociacao` e os dados históricos presentes na tabela `data`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToTm8e6chF09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "318efae9-28bc-4cbb-974e-26c11c89a40a"
      },
      "source": [
        "# Resposta do exercício\n",
        "query = \"\"\"\n",
        "SELECT CAST(SUM(quantidadeNegociacoes) AS INTEGER) AS `Quantidade de Negociações`\n",
        "FROM data JOIN negociacao ON (data.dataPK = negociacao.dataPK) \n",
        "WHERE dataAno = 2016\n",
        "      AND dataTrimestre = 2\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------+\n",
            "|Quantidade de Negociações|\n",
            "+-------------------------+\n",
            "|                       59|\n",
            "+-------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crCnMYwi7rIm"
      },
      "source": [
        "## 5.2 Operações Drill-Down e Roll-Up\n",
        "\n",
        "**Definição**: Analisam os dados considerando níveis progressivos de agregação.\n",
        "\n",
        "- Drill-down: níveis de agregação progressivamente mais detalhados, ou de menor granularidade.\n",
        "- Roll-up: níveis de agregação progressivamente menos detalhados, ou de maior granularidade."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YC-qVTVIpyX4"
      },
      "source": [
        "Para ilustrar as operações de drill-down e roll-up, considere a consulta base definida a seguir.\n",
        "\n",
        "**Consulta base:** Qual o valor gasto em salários por ano, considerando cada **semestre**?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnaUOx3uow4Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7c4ce10-4e43-441b-861f-a8a27a163023"
      },
      "source": [
        "query = \"\"\"\n",
        "SELECT dataAno, dataSemestre, ROUND(SUM(salario),2) AS `Valor gasto em salários por semestre`\n",
        "FROM data JOIN pagamento ON data.dataPK = pagamento.dataPK \n",
        "GROUP BY dataAno, dataSemestre\n",
        "ORDER BY dataAno, dataSemestre\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+------------------------------------+\n",
            "|dataAno|dataSemestre|Valor gasto em salários por semestre|\n",
            "+-------+------------+------------------------------------+\n",
            "|   2016|           1|                          2221308.54|\n",
            "|   2016|           2|                          2221308.54|\n",
            "|   2017|           1|                           4887639.9|\n",
            "|   2017|           2|                           4887639.9|\n",
            "|   2018|           1|                           7467763.2|\n",
            "|   2018|           2|                           7467763.2|\n",
            "|   2019|           1|                          9283833.18|\n",
            "|   2019|           2|                          9283833.18|\n",
            "|   2020|           1|                          9283833.18|\n",
            "|   2020|           2|                          9283833.18|\n",
            "+-------+------------+------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PzzQT1Xz-4-"
      },
      "source": [
        "**Exemplo de consulta drill-down:** Qual o valor gasto em salários por ano, considerando cada **trimestre**?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8EZJPBSquj4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f65d013-43eb-4519-f7ed-de7c79ceb73e"
      },
      "source": [
        "query = \"\"\"\n",
        "SELECT dataAno, dataTrimestre, ROUND(SUM(salario),2) AS `Valor gasto em salários por trimestre`\n",
        "FROM data JOIN pagamento ON (data.dataPK = pagamento.dataPK) \n",
        "GROUP BY dataAno, dataTrimestre\n",
        "ORDER BY dataAno, dataTrimestre\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------------+-------------------------------------+\n",
            "|dataAno|dataTrimestre|Valor gasto em salários por trimestre|\n",
            "+-------+-------------+-------------------------------------+\n",
            "|   2016|            1|                           1110654.27|\n",
            "|   2016|            2|                           1110654.27|\n",
            "|   2016|            3|                           1110654.27|\n",
            "|   2016|            4|                           1110654.27|\n",
            "|   2017|            1|                           2443819.95|\n",
            "|   2017|            2|                           2443819.95|\n",
            "|   2017|            3|                           2443819.95|\n",
            "|   2017|            4|                           2443819.95|\n",
            "|   2018|            1|                            3733881.6|\n",
            "|   2018|            2|                            3733881.6|\n",
            "|   2018|            3|                            3733881.6|\n",
            "|   2018|            4|                            3733881.6|\n",
            "|   2019|            1|                           4641916.59|\n",
            "|   2019|            2|                           4641916.59|\n",
            "|   2019|            3|                           4641916.59|\n",
            "|   2019|            4|                           4641916.59|\n",
            "|   2020|            1|                           4641916.59|\n",
            "|   2020|            2|                           4641916.59|\n",
            "|   2020|            3|                           4641916.59|\n",
            "|   2020|            4|                           4641916.59|\n",
            "+-------+-------------+-------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bFWeBr87xpN"
      },
      "source": [
        "**Exemplo de consulta roll-up:** Qual o valor gasto em salários por **ano**?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPKhALIJrllz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c646a074-a7d2-427e-be06-abb067237df7"
      },
      "source": [
        "query = \"\"\"\n",
        "SELECT dataAno, ROUND(SUM(salario),2) AS `Valor gasto em salários por ano`\n",
        "FROM data JOIN pagamento ON (data.dataPK = pagamento.dataPK) \n",
        "GROUP BY dataAno\n",
        "ORDER BY dataAno\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------------------------------+\n",
            "|dataAno|Valor gasto em salários por ano|\n",
            "+-------+-------------------------------+\n",
            "|   2016|                     4442617.08|\n",
            "|   2017|                      9775279.8|\n",
            "|   2018|                   1.49355264E7|\n",
            "|   2019|                  1.856766636E7|\n",
            "|   2020|                  1.856766636E7|\n",
            "+-------+-------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nG_cvrxlrdx7"
      },
      "source": [
        "### **EXERCÍCIO 2 (Essencial)** \n",
        "\n",
        "Faça 3 consultas SQL, uma para cada consulta especificada a seguir.\n",
        "\n",
        "- **Consulta base:** Qual é a soma da receita recebida em cada um dos semestres do ano de 2019? Renomeie o resultado final como \"Valor recebido em receitas por semestre no ano de 2019\".\n",
        "\n",
        "- **Consulta drill-down:** Qual é a soma da receita recebida em cada um dos trimestres do ano de 2019? Renomeie o resultado final como \"Valor recebido em receitas por trimestre no ano de 2019\".\n",
        "\n",
        "- **Consulta roll-up:** Qual é a soma da receita recebida no ano de 2019? Renomeie o resultado final como \"Valor recebido em receitas no ano de 2019\".\n",
        "\n",
        "Dica: utilize a medida numérica `receita` presente na tabela `negociacao` e os dados históricos presentes na tabela `data`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRzqGoTnw5cG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84ba455c-393c-4519-fff0-a52683a03a2c"
      },
      "source": [
        "# Resposta do exercício - consulta base\n",
        "query = \"\"\"\n",
        "SELECT dataAno, dataSemestre, ROUND(SUM(receita),2) AS `Valor recebido em receitas por semestre no ano de 2019`\n",
        "FROM data JOIN negociacao ON data.dataPK = negociacao.dataPK\n",
        "WHERE dataAno = 2019\n",
        "GROUP BY dataAno, dataSemestre\n",
        "ORDER BY dataAno, dataSemestre\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+------------------------------------------------------+\n",
            "|dataAno|dataSemestre|Valor recebido em receitas por semestre no ano de 2019|\n",
            "+-------+------------+------------------------------------------------------+\n",
            "|   2019|           1|                                         1.832852695E7|\n",
            "|   2019|           2|                                         1.702479135E7|\n",
            "+-------+------------+------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_wIArbCyHtO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d979182e-7e51-4180-a801-278cde683210"
      },
      "source": [
        "# Resposta do exercício - consulta drill-down\n",
        "query = \"\"\"\n",
        "SELECT dataAno, dataTrimestre, ROUND(SUM(receita),2) AS `Valor recebido em receitas por trimestre no ano de 2019`\n",
        "FROM data JOIN negociacao ON data.dataPK = negociacao.dataPK\n",
        "WHERE dataAno = 2019\n",
        "GROUP BY dataAno, dataTrimestre\n",
        "ORDER BY dataAno, dataTrimestre\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------------+-------------------------------------------------------+\n",
            "|dataAno|dataTrimestre|Valor recebido em receitas por trimestre no ano de 2019|\n",
            "+-------+-------------+-------------------------------------------------------+\n",
            "|   2019|            1|                                              9089432.5|\n",
            "|   2019|            2|                                             9239094.45|\n",
            "|   2019|            3|                                              8792711.2|\n",
            "|   2019|            4|                                             8232080.15|\n",
            "+-------+-------------+-------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylFLmjXkyhx8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d519bc1e-453a-47f9-a6d1-c3f24541f5a8"
      },
      "source": [
        "# Resposta do exercício - consulta roll-up\n",
        "query = \"\"\"\n",
        "SELECT dataAno, ROUND(SUM(receita),2) AS `Valor recebido em receitas no ano de 2019`\n",
        "FROM data JOIN negociacao ON data.dataPK = negociacao.dataPK\n",
        "WHERE dataAno = 2019\n",
        "GROUP BY dataAno\n",
        "ORDER BY dataAno\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------------------------------+\n",
            "|dataAno|Valor recebido em receitas no ano de 2019|\n",
            "+-------+-----------------------------------------+\n",
            "|   2019|                             3.53533183E7|\n",
            "+-------+-----------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1kRDhciLQnj"
      },
      "source": [
        "## 5.3 Operação Pivot\n",
        "\n",
        "**Definição:** Reorienta a visão multidimensional dos dados, oferecendo diferentes perspectivas dos mesmos dados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaXAXkeF1atH"
      },
      "source": [
        "Para ilustrar a operação pivot, considere a consulta base definida a seguir. \n",
        "\n",
        "**Consulta base:**  Qual o valor gasto em salários por ano, considerando cada nível de cargo?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiA8yW23o9H5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d85467c-58a4-42af-9b57-1b6d7351569f"
      },
      "source": [
        "query = \"\"\"\n",
        "SELECT dataAno, cargoNivel, ROUND(SUM(salario),2) AS `Gastos em Salários`\n",
        "FROM pagamento JOIN data ON pagamento.dataPK = data.dataPK \n",
        "               JOIN cargo ON pagamento.cargoPK = cargo.cargoPK \n",
        "GROUP BY dataAno, cargoNivel\n",
        "ORDER BY dataAno, cargoNivel\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+------------------+\n",
            "|dataAno|cargoNivel|Gastos em Salários|\n",
            "+-------+----------+------------------+\n",
            "|   2016|    JUNIOR|         489456.84|\n",
            "|   2016|     PLENO|        1454152.44|\n",
            "|   2016|    SENIOR|         2499007.8|\n",
            "|   2017|    JUNIOR|         1030642.8|\n",
            "|   2017|     PLENO|        3791593.92|\n",
            "|   2017|    SENIOR|        4953043.08|\n",
            "|   2018|    JUNIOR|         1393282.2|\n",
            "|   2018|     PLENO|        5357227.44|\n",
            "|   2018|    SENIOR|        8185016.76|\n",
            "|   2019|    JUNIOR|        1755714.36|\n",
            "|   2019|     PLENO|        6132228.24|\n",
            "|   2019|    SENIOR|     1.067972376E7|\n",
            "|   2020|    JUNIOR|        1755714.36|\n",
            "|   2020|     PLENO|        6132228.24|\n",
            "|   2020|    SENIOR|     1.067972376E7|\n",
            "+-------+----------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPBaswdrLWv6"
      },
      "source": [
        "**Exemplo de consulta pivot:** Qual o valor gasto em salários por nível de cargo, considerando cada ano?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v63e5Yps2CSD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e064db61-034d-4f5b-e79b-ff3120e2ae78"
      },
      "source": [
        "query = \"\"\"\n",
        "SELECT cargoNivel, dataAno, ROUND(SUM(salario),2) AS `Gastos em Salários`\n",
        "FROM pagamento JOIN data ON pagamento.dataPK = data.dataPK \n",
        "               JOIN cargo ON pagamento.cargoPK = cargo.cargoPK \n",
        "GROUP BY cargoNivel, dataAno\n",
        "ORDER BY cargoNivel, dataAno\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------+------------------+\n",
            "|cargoNivel|dataAno|Gastos em Salários|\n",
            "+----------+-------+------------------+\n",
            "|    JUNIOR|   2016|         489456.84|\n",
            "|    JUNIOR|   2017|         1030642.8|\n",
            "|    JUNIOR|   2018|         1393282.2|\n",
            "|    JUNIOR|   2019|        1755714.36|\n",
            "|    JUNIOR|   2020|        1755714.36|\n",
            "|     PLENO|   2016|        1454152.44|\n",
            "|     PLENO|   2017|        3791593.92|\n",
            "|     PLENO|   2018|        5357227.44|\n",
            "|     PLENO|   2019|        6132228.24|\n",
            "|     PLENO|   2020|        6132228.24|\n",
            "|    SENIOR|   2016|         2499007.8|\n",
            "|    SENIOR|   2017|        4953043.08|\n",
            "|    SENIOR|   2018|        8185016.76|\n",
            "|    SENIOR|   2019|     1.067972376E7|\n",
            "|    SENIOR|   2020|     1.067972376E7|\n",
            "+----------+-------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FNsObn_vVmp"
      },
      "source": [
        "### **EXERCÍCIO 3 (Essencial)**\n",
        "\n",
        "Faça 2 consultas SQL, uma para cada consulta especificada a seguir.\n",
        "\n",
        "- **Consulta base:** Qual é a receita média gerada pelos clientes considerando seus segmentos (ou seja, os setores nos quais eles atuam), em cada um dos anos? Renomeie o resultado final como \"Total de Receitas\".\n",
        "\n",
        "- **Consulta pivot:** Qual é a receita média gerada pelos clientes em cada um dos anos, considerando seus segmentos (ou seja, os setores nos quais eles atuam)? Renomeie o resultado final como \"Total de Receitas\".\n",
        "\n",
        "Dica: utilize a medida numérica `receita` presente na tabela `negociacao`, os dados de clientes presentes na tabela `cliente` e os dados históricos presentes na tabela `data`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVwVfF5RHF_n",
        "outputId": "4e1153a5-13f7-4838-9ebd-202652e1f2cb"
      },
      "source": [
        "negociacao.columns"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['equipePK', 'clientePK', 'dataPK', 'receita', 'quantidadeNegociacoes']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbMFuwy5HdEd",
        "outputId": "35c4e07f-2840-4eb2-f5b9-20a8787e9630"
      },
      "source": [
        "cliente.columns"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['clientePK',\n",
              " 'clienteNomeFantasia',\n",
              " 'clienteSetor',\n",
              " 'clienteCidade',\n",
              " 'clienteEstadoNome',\n",
              " 'clienteEstadoSigla',\n",
              " 'clienteRegiaoNome',\n",
              " 'clienteRegiaoSigla',\n",
              " 'clientePaisNome',\n",
              " 'clientePaisSigla']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocDbNvCS6irD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f873f6eb-57e2-4f62-f766-f60b43994117"
      },
      "source": [
        "# Resposta do exercício - consulta base\n",
        "query = \"\"\"\n",
        "SELECT clienteSetor, dataAno, ROUND(AVG(receita),2) AS `Total de Receitas`\n",
        "FROM negociacao JOIN data ON negociacao.dataPK = data.dataPK \n",
        "               JOIN cliente ON negociacao.clientePK = cliente.clientePK \n",
        "GROUP BY clienteSetor, dataAno\n",
        "ORDER BY clienteSetor, dataAno\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-------+-----------------+\n",
            "|       clienteSetor|dataAno|Total de Receitas|\n",
            "+-------------------+-------+-----------------+\n",
            "|BEBIDAS E ALIMENTOS|   2016|          16289.1|\n",
            "|BEBIDAS E ALIMENTOS|   2017|         14090.94|\n",
            "|BEBIDAS E ALIMENTOS|   2018|         13748.01|\n",
            "|BEBIDAS E ALIMENTOS|   2019|         22625.97|\n",
            "|BEBIDAS E ALIMENTOS|   2020|         23022.96|\n",
            "|            CREDITO|   2016|         12478.54|\n",
            "|            CREDITO|   2017|         15512.85|\n",
            "|            CREDITO|   2018|         15081.67|\n",
            "|            CREDITO|   2019|         34543.42|\n",
            "|            CREDITO|   2020|         32824.57|\n",
            "|              SAUDE|   2016|         19920.16|\n",
            "|              SAUDE|   2017|         11033.73|\n",
            "|              SAUDE|   2018|         13804.84|\n",
            "|              SAUDE|   2019|         34020.14|\n",
            "|              SAUDE|   2020|          30274.9|\n",
            "|         TECNOLOGIA|   2016|         15391.56|\n",
            "|         TECNOLOGIA|   2017|          13458.9|\n",
            "|         TECNOLOGIA|   2018|         13690.66|\n",
            "|         TECNOLOGIA|   2019|         34555.96|\n",
            "|         TECNOLOGIA|   2020|         26883.52|\n",
            "+-------------------+-------+-----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vau9iY6dhx-P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57aed3a2-87b2-4bd7-bb84-afae16e6028e"
      },
      "source": [
        "# Resposta do exercício - consulta pivot\n",
        "query = \"\"\"\n",
        "SELECT dataAno, clienteSetor, ROUND(AVG(receita),2) AS `Total de Receitas`\n",
        "FROM negociacao JOIN data ON negociacao.dataPK = data.dataPK \n",
        "               JOIN cliente ON negociacao.clientePK = cliente.clientePK \n",
        "GROUP BY dataAno, clienteSetor\n",
        "ORDER BY dataAno, clienteSetor\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------------------+-----------------+\n",
            "|dataAno|       clienteSetor|Total de Receitas|\n",
            "+-------+-------------------+-----------------+\n",
            "|   2016|BEBIDAS E ALIMENTOS|          16289.1|\n",
            "|   2016|            CREDITO|         12478.54|\n",
            "|   2016|              SAUDE|         19920.16|\n",
            "|   2016|         TECNOLOGIA|         15391.56|\n",
            "|   2016|          VESTUARIO|         20544.94|\n",
            "|   2017|BEBIDAS E ALIMENTOS|         14090.94|\n",
            "|   2017|            CREDITO|         15512.85|\n",
            "|   2017|              SAUDE|         11033.73|\n",
            "|   2017|         TECNOLOGIA|          13458.9|\n",
            "|   2017|          VESTUARIO|         11848.01|\n",
            "|   2018|BEBIDAS E ALIMENTOS|         13748.01|\n",
            "|   2018|            CREDITO|         15081.67|\n",
            "|   2018|              SAUDE|         13804.84|\n",
            "|   2018|         TECNOLOGIA|         13690.66|\n",
            "|   2018|          VESTUARIO|         12347.27|\n",
            "|   2019|BEBIDAS E ALIMENTOS|         22625.97|\n",
            "|   2019|            CREDITO|         34543.42|\n",
            "|   2019|              SAUDE|         34020.14|\n",
            "|   2019|         TECNOLOGIA|         34555.96|\n",
            "|   2019|          VESTUARIO|          32297.8|\n",
            "+-------+-------------------+-----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtJILugUN2K_"
      },
      "source": [
        "## 5.4 Operação Drill-Across\n",
        "\n",
        "**Definição:** Compara medidas numéricas de tabelas de fatos diferentes, utilizando pelo menos uma dimensão em comum. \n",
        "\n",
        "**Exemplo de consulta:** Qual o total gasto com salários e qual o total de receitas recebidas, considerando cada ano?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ROfs12PMRN6",
        "outputId": "cfcdd138-3a90-46ef-fed4-323e315f557c"
      },
      "source": [
        "pagamento.columns"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['funcPK', 'equipePK', 'dataPK', 'cargoPK', 'salario', 'quantidadeLancamentos']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyoWQDJiIgQx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0f504a8-523b-4335-8fb2-fda045eb9aa0"
      },
      "source": [
        "# utilizando a cláusula JOIN ... ON ...\n",
        "query = \"\"\"\n",
        "SELECT anoPag AS `Ano`, ROUND(salario,2) AS `Total Gasto com Salários`, ROUND(receita,2) AS `Total de Receitas Recebidas`\n",
        "FROM ( SELECT dataAno, SUM(salario)  \n",
        "       FROM pagamento JOIN data on data.dataPK = pagamento.dataPK\n",
        "       GROUP BY dataAno\n",
        "      ) AS pag(anoPag, salario)\n",
        "     JOIN \n",
        "     ( SELECT dataAno, SUM(receita)\n",
        "       FROM negociacao JOIN data ON data.dataPK = negociacao.dataPK\n",
        "       GROUP BY dataAno\n",
        "      ) AS neg(anoNeg, receita) \n",
        "     ON anoPag = anoNeg \n",
        "ORDER BY anoPag\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------------------------+---------------------------+\n",
            "| Ano|Total Gasto com Salários|Total de Receitas Recebidas|\n",
            "+----+------------------------+---------------------------+\n",
            "|2016|              4442617.08|                 4614246.95|\n",
            "|2017|               9775279.8|                 7200423.35|\n",
            "|2018|            1.49355264E7|              1.159353965E7|\n",
            "|2019|           1.856766636E7|               3.53533183E7|\n",
            "|2020|           1.856766636E7|              3.022217595E7|\n",
            "+----+------------------------+---------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CP9gstSQ9XUu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b0187da-2608-44f0-b7d1-955422b66862"
      },
      "source": [
        "# utilizando a cláusula WHERE\n",
        "query = \"\"\"\n",
        "SELECT anoPag AS `Ano`, ROUND(salario,2) AS `Total Gasto com Salários`, ROUND(receita,2) AS `Total de Receitas Recebidas`\n",
        "FROM ( SELECT dataAno, SUM(salario) \n",
        "       FROM pagamento JOIN data on data.dataPK = pagamento.dataPK\n",
        "       GROUP BY dataAno\n",
        "      ) AS pag(anoPag, salario), \n",
        "     ( SELECT dataAno, SUM(receita)\n",
        "       FROM negociacao JOIN data ON data.dataPK = negociacao.dataPK\n",
        "       GROUP BY dataAno\n",
        "      ) AS neg(anoNeg, receita) \n",
        "WHERE anoPag = anoNeg \n",
        "ORDER BY anoPag\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------------------------+---------------------------+\n",
            "| Ano|Total Gasto com Salários|Total de Receitas Recebidas|\n",
            "+----+------------------------+---------------------------+\n",
            "|2016|              4442617.08|                 4614246.95|\n",
            "|2017|               9775279.8|                 7200423.35|\n",
            "|2018|            1.49355264E7|              1.159353965E7|\n",
            "|2019|           1.856766636E7|               3.53533183E7|\n",
            "|2020|           1.856766636E7|              3.022217595E7|\n",
            "+----+------------------------+---------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1qyZMktxuwc"
      },
      "source": [
        "### **EXERCÍCIO 4 (Essencial)**\n",
        "\n",
        "Qual o total gasto em salários e qual o total de receitas recebidas, considerando apenas os anos de 2017, 2018 e 2019? Renomeie a saída para \"Ano\", \"Total Gasto com Salários\" e \"Total de Receitas Recebidas\".\n",
        "\n",
        "Dica: utilize a medida numérica `salario` da tabela `pagamento`, a medida numérica `receita` da tabela `negociacao` e os dados históricos presentes na tabela `data`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHMnaRdr-xe6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e3cc69d-68a3-4681-b0ad-74d361d90f8b"
      },
      "source": [
        "# Resposta do exercício\n",
        "# utilizando a cláusula JOIN ... ON ...\n",
        "query = \"\"\"\n",
        "SELECT anoPag AS `Ano`, ROUND(salario,2) AS `Total Gasto com Salários`, ROUND(receita,2) AS `Total de Receitas Recebidas`\n",
        "FROM ( SELECT dataAno, SUM(salario)  \n",
        "       FROM pagamento JOIN data on data.dataPK = pagamento.dataPK\n",
        "       GROUP BY dataAno\n",
        "      ) AS pag(anoPag, salario)\n",
        "     JOIN \n",
        "     ( SELECT dataAno, SUM(receita)\n",
        "       FROM negociacao JOIN data ON data.dataPK = negociacao.dataPK\n",
        "       GROUP BY dataAno\n",
        "      ) AS neg(anoNeg, receita) \n",
        "     ON anoPag = anoNeg\n",
        "     WHERE anoPag BETWEEN 2017 AND 2019\n",
        "ORDER BY anoPag\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------------------------+---------------------------+\n",
            "| Ano|Total Gasto com Salários|Total de Receitas Recebidas|\n",
            "+----+------------------------+---------------------------+\n",
            "|2017|               9775279.8|                 7200423.35|\n",
            "|2018|            1.49355264E7|              1.159353965E7|\n",
            "|2019|           1.856766636E7|               3.53533183E7|\n",
            "+----+------------------------+---------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTjo_CX1G5jy"
      },
      "source": [
        "## 5.5 Extensões ROLLUP, CUBE e GROUPING SETS \n",
        "\n",
        "**Definição:** Constrém vários níveis de agregação.\n",
        "\n",
        "- ROLLUP: criação de subtotais para as combinações dos atributos da lista de agrupamento de acordo com a ordem desses atributos. São criados n+1 níveis de agregação, sendo n o número de atributos especificados na lista de agrupamento.\n",
        "\n",
        "- CUBE: criação de subtotais para todas as combinações dos atributos da lista de agrupamento. São criados 2ˆn (2 elevado a n) níveis, sendo n o número de atributos especificados na lista de agrupamento.\n",
        "\n",
        "- GROUPING SETS: criação de subtotais para quaisquer combinações de atributos de agrupamentos. É criada a quantidade de subtotais especificados na lista de níveis de agregação desejados. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RRlVccmYhV_"
      },
      "source": [
        "\n",
        "**Exemplo de consulta com ROLLUP:** Liste as agregações que podem ser geradas a partir da soma da receita por setor do cliente e por cidade do cliente, para totais de receita superiores a 3.000.000,00. Crie subtotais considerando a ordem dos atributos na lista de agrupamento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwZHLSsCW0zD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97910b7d-410a-4a14-9b5e-3f358af6ae72"
      },
      "source": [
        "query = \"\"\"\n",
        "SELECT clienteSetor, clientecidade, ROUND(SUM(receita),2) AS `Total de Receitas`\n",
        "FROM cliente JOIN negociacao ON cliente.clientePk = negociacao.clientePK\n",
        "GROUP BY ROLLUP (clienteSetor, clienteCidade)\n",
        "HAVING SUM(receita) > 3000000\n",
        "ORDER BY clienteSetor, clienteCidade\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------+-----------------+\n",
            "|       clienteSetor| clienteCidade|Total de Receitas|\n",
            "+-------------------+--------------+-----------------+\n",
            "|               null|          null|     8.89837042E7|\n",
            "|BEBIDAS E ALIMENTOS|          null|     3.54087859E7|\n",
            "|BEBIDAS E ALIMENTOS|BELO HORIZONTE|        4206811.8|\n",
            "|BEBIDAS E ALIMENTOS|       MARILIA|        4033680.5|\n",
            "|BEBIDAS E ALIMENTOS|        RECIFE|        3899358.3|\n",
            "|BEBIDAS E ALIMENTOS|RIO DE JANEIRO|       7351629.95|\n",
            "|BEBIDAS E ALIMENTOS|     SAO PAULO|        6177945.5|\n",
            "|BEBIDAS E ALIMENTOS|    UBERLANDIA|       3283351.55|\n",
            "|            CREDITO|          null|        6621387.7|\n",
            "|              SAUDE|          null|    1.831261245E7|\n",
            "|              SAUDE|        MANAUS|       3329638.25|\n",
            "|              SAUDE|     SAO PAULO|       3963055.35|\n",
            "|         TECNOLOGIA|          null|      1.6568033E7|\n",
            "|         TECNOLOGIA|     SAO PAULO|        9200352.8|\n",
            "|          VESTUARIO|          null|    1.207288515E7|\n",
            "|          VESTUARIO|RIO DE JANEIRO|        5948448.1|\n",
            "|          VESTUARIO|     SAO PAULO|        4686200.3|\n",
            "+-------------------+--------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUFL8-CcYojA"
      },
      "source": [
        "**Exemplo de consulta com GROUPING SETS com semântica de ROLLUP:** Liste todas as agregações que podem ser geradas a partir da soma da receita por setor do cliente e por cidade do cliente, para totais de receita superiores a 3.000.000,00. Crie subtotais considerando a ordem dos atributos na lista de agrupamento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tq9x3HMyPwHe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b484a33-55f1-4305-c227-8d1829b4d0cb"
      },
      "source": [
        "query = \"\"\"\n",
        "SELECT clienteSetor, clientecidade, ROUND(SUM(receita),2) AS `Total de Receitas`\n",
        "FROM cliente JOIN negociacao ON cliente.clientePk = negociacao.clientePK\n",
        "GROUP BY GROUPING SETS ((clienteSetor, clienteCidade), (clienteSetor), ())\n",
        "HAVING SUM(receita) > 3000000\n",
        "ORDER BY clienteSetor, clienteCidade\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------+-----------------+\n",
            "|       clienteSetor| clienteCidade|Total de Receitas|\n",
            "+-------------------+--------------+-----------------+\n",
            "|               null|          null|     8.89837042E7|\n",
            "|BEBIDAS E ALIMENTOS|          null|     3.54087859E7|\n",
            "|BEBIDAS E ALIMENTOS|BELO HORIZONTE|        4206811.8|\n",
            "|BEBIDAS E ALIMENTOS|       MARILIA|        4033680.5|\n",
            "|BEBIDAS E ALIMENTOS|        RECIFE|        3899358.3|\n",
            "|BEBIDAS E ALIMENTOS|RIO DE JANEIRO|       7351629.95|\n",
            "|BEBIDAS E ALIMENTOS|     SAO PAULO|        6177945.5|\n",
            "|BEBIDAS E ALIMENTOS|    UBERLANDIA|       3283351.55|\n",
            "|            CREDITO|          null|        6621387.7|\n",
            "|              SAUDE|          null|    1.831261245E7|\n",
            "|              SAUDE|        MANAUS|       3329638.25|\n",
            "|              SAUDE|     SAO PAULO|       3963055.35|\n",
            "|         TECNOLOGIA|          null|      1.6568033E7|\n",
            "|         TECNOLOGIA|     SAO PAULO|        9200352.8|\n",
            "|          VESTUARIO|          null|    1.207288515E7|\n",
            "|          VESTUARIO|RIO DE JANEIRO|        5948448.1|\n",
            "|          VESTUARIO|     SAO PAULO|        4686200.3|\n",
            "+-------------------+--------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjjDB_mtPkzw"
      },
      "source": [
        "**Exemplo de consulta com CUBE:** Liste todas as agregações que podem ser geradas a partir da soma da receita por setor do cliente e por cidade do cliente, para totais de receita superiores a 3.000.000,00."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_5lF9EVFZr6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5b8dd91-9fda-4124-bfc7-5c3d27dde137"
      },
      "source": [
        "query = \"\"\"\n",
        "SELECT clienteSetor, clientecidade, ROUND(SUM(receita),2) AS `Total de Receitas`\n",
        "FROM cliente JOIN negociacao ON cliente.clientePk = negociacao.clientePK\n",
        "GROUP BY CUBE (clienteSetor, clienteCidade)\n",
        "HAVING SUM(receita) > 3000000\n",
        "ORDER BY clienteSetor, clienteCidade\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show(40)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------+-----------------+\n",
            "|       clienteSetor| clienteCidade|Total de Receitas|\n",
            "+-------------------+--------------+-----------------+\n",
            "|               null|          null|     8.89837042E7|\n",
            "|               null|BELO HORIZONTE|       4379523.85|\n",
            "|               null|  CAMPO GRANDE|       3422117.05|\n",
            "|               null|      CURITIBA|       3697625.35|\n",
            "|               null|     FORTALEZA|       3391233.25|\n",
            "|               null|        MANAUS|       5234539.25|\n",
            "|               null|       MARILIA|        7289146.1|\n",
            "|               null|  PORTO ALEGRE|        4319625.7|\n",
            "|               null|        RECIFE|       4717719.45|\n",
            "|               null|RIO DE JANEIRO|    1.525596265E7|\n",
            "|               null|    SAO CARLOS|       4192741.95|\n",
            "|               null|     SAO PAULO|    2.464599965E7|\n",
            "|               null|    UBERLANDIA|        4357595.2|\n",
            "|BEBIDAS E ALIMENTOS|          null|     3.54087859E7|\n",
            "|BEBIDAS E ALIMENTOS|BELO HORIZONTE|        4206811.8|\n",
            "|BEBIDAS E ALIMENTOS|       MARILIA|        4033680.5|\n",
            "|BEBIDAS E ALIMENTOS|        RECIFE|        3899358.3|\n",
            "|BEBIDAS E ALIMENTOS|RIO DE JANEIRO|       7351629.95|\n",
            "|BEBIDAS E ALIMENTOS|     SAO PAULO|        6177945.5|\n",
            "|BEBIDAS E ALIMENTOS|    UBERLANDIA|       3283351.55|\n",
            "|            CREDITO|          null|        6621387.7|\n",
            "|              SAUDE|          null|    1.831261245E7|\n",
            "|              SAUDE|        MANAUS|       3329638.25|\n",
            "|              SAUDE|     SAO PAULO|       3963055.35|\n",
            "|         TECNOLOGIA|          null|      1.6568033E7|\n",
            "|         TECNOLOGIA|     SAO PAULO|        9200352.8|\n",
            "|          VESTUARIO|          null|    1.207288515E7|\n",
            "|          VESTUARIO|RIO DE JANEIRO|        5948448.1|\n",
            "|          VESTUARIO|     SAO PAULO|        4686200.3|\n",
            "+-------------------+--------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZ0y48oPbwiO"
      },
      "source": [
        "**Exemplo de consulta com GROUPING SETS com semântica de CUBE:** Liste todas as agregações que podem ser geradas a partir da soma da receita por setor do cliente e por cidade do cliente, para totais de receita superiores a 3.000.000,00. Crie subtotais considerando a ordem dos atributos na lista de agrupamento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8oaCRpEb29W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48828a73-2bc7-4c79-d978-87bc6b7b9be0"
      },
      "source": [
        "query = \"\"\"\n",
        "SELECT clienteSetor, clientecidade, ROUND(SUM(receita),2) AS `Total de Receitas`\n",
        "FROM cliente JOIN negociacao ON cliente.clientePk = negociacao.clientePK\n",
        "GROUP BY GROUPING SETS ((clienteSetor, clienteCidade), (clienteSetor), (clienteCidade), ())\n",
        "HAVING SUM(receita) > 3000000\n",
        "ORDER BY clienteSetor, clienteCidade\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show(40)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------+-----------------+\n",
            "|       clienteSetor| clienteCidade|Total de Receitas|\n",
            "+-------------------+--------------+-----------------+\n",
            "|               null|          null|     8.89837042E7|\n",
            "|               null|BELO HORIZONTE|       4379523.85|\n",
            "|               null|  CAMPO GRANDE|       3422117.05|\n",
            "|               null|      CURITIBA|       3697625.35|\n",
            "|               null|     FORTALEZA|       3391233.25|\n",
            "|               null|        MANAUS|       5234539.25|\n",
            "|               null|       MARILIA|        7289146.1|\n",
            "|               null|  PORTO ALEGRE|        4319625.7|\n",
            "|               null|        RECIFE|       4717719.45|\n",
            "|               null|RIO DE JANEIRO|    1.525596265E7|\n",
            "|               null|    SAO CARLOS|       4192741.95|\n",
            "|               null|     SAO PAULO|    2.464599965E7|\n",
            "|               null|    UBERLANDIA|        4357595.2|\n",
            "|BEBIDAS E ALIMENTOS|          null|     3.54087859E7|\n",
            "|BEBIDAS E ALIMENTOS|BELO HORIZONTE|        4206811.8|\n",
            "|BEBIDAS E ALIMENTOS|       MARILIA|        4033680.5|\n",
            "|BEBIDAS E ALIMENTOS|        RECIFE|        3899358.3|\n",
            "|BEBIDAS E ALIMENTOS|RIO DE JANEIRO|       7351629.95|\n",
            "|BEBIDAS E ALIMENTOS|     SAO PAULO|        6177945.5|\n",
            "|BEBIDAS E ALIMENTOS|    UBERLANDIA|       3283351.55|\n",
            "|            CREDITO|          null|        6621387.7|\n",
            "|              SAUDE|          null|    1.831261245E7|\n",
            "|              SAUDE|        MANAUS|       3329638.25|\n",
            "|              SAUDE|     SAO PAULO|       3963055.35|\n",
            "|         TECNOLOGIA|          null|      1.6568033E7|\n",
            "|         TECNOLOGIA|     SAO PAULO|        9200352.8|\n",
            "|          VESTUARIO|          null|    1.207288515E7|\n",
            "|          VESTUARIO|RIO DE JANEIRO|        5948448.1|\n",
            "|          VESTUARIO|     SAO PAULO|        4686200.3|\n",
            "+-------------------+--------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgV9cze8MBY3"
      },
      "source": [
        "# 6 Execução de Consultas com Foco na Tomada de Decisão\n",
        "As consultas OLAP requisitadas por usuários de sistemas de suporte à decisão usualmente requerem que várias operações OLAP sejam realizadas simultaneamente. A seguir são ilustrados exemplos de consultas OLAP que podem ser requisitadas para a tomada de decisão estratégica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcaRLxX_Jd1w"
      },
      "source": [
        "## 6.1 Consulta 1\n",
        "\n",
        "Qual é a média dos salários recebidos por nível do cargo e por sexo no ano de 2019?\n",
        "\n",
        "Para se realizar esta consulta, é necessário obter dados das tabelas de dimensão `cargo`, `funcionario` e `data`, bem como da tabela de fatos `pagamento`. A junção estrela deve ocorrer considerando as seguintes integridades referenciais:\n",
        "- `pagamento.cargoPK = cargo.cargoPK`\n",
        "- `pagamento.funcPK = funcionario.funcPK`\n",
        "- `pagamento.dataPK = data.dataPK` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeKlyc-mMt64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c14e248c-8e2f-4be3-d0be-7c498b991803"
      },
      "source": [
        "# utilizando a cláusula JOIN ... ON ...\n",
        "query = \"\"\"\n",
        "SELECT cargoNivel, funcSexo, ROUND(AVG(salario),2) AS `Média dos Salários`\n",
        "FROM pagamento JOIN data ON data.dataPK = pagamento.dataPK\n",
        "               JOIN cargo ON cargo.cargoPK = pagamento.cargoPK\n",
        "               JOIN funcionario ON funcionario.funcPK = pagamento.funcPK \n",
        "WHERE dataAno = 2019\n",
        "GROUP BY cargoNivel, funcSexo\n",
        "ORDER BY cargoNivel, funcSexo\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------+------------------+\n",
            "|cargoNivel|funcSexo|Média dos Salários|\n",
            "+----------+--------+------------------+\n",
            "|    JUNIOR|       F|           2440.23|\n",
            "|    JUNIOR|       M|           2437.86|\n",
            "|     PLENO|       F|           7641.94|\n",
            "|     PLENO|       M|           6259.61|\n",
            "|    SENIOR|       F|          12994.19|\n",
            "|    SENIOR|       M|           14480.5|\n",
            "+----------+--------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "so-Hec1xeZHL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59c5b42b-6c77-4859-9636-78c562785022"
      },
      "source": [
        "# utilizando a cláusula WHERE\n",
        "query = \"\"\"\n",
        "SELECT cargoNivel, funcSexo, ROUND(AVG(salario),2) AS `Média dos Salários`\n",
        "FROM pagamento, cargo, funcionario, data\n",
        "WHERE data.dataPK = pagamento.dataPK\n",
        "      AND cargo.cargoPK = pagamento.cargoPK\n",
        "      AND funcionario.funcPK = pagamento.funcPK\n",
        "      AND dataAno = 2019\n",
        "GROUP BY cargoNivel, funcSexo\n",
        "ORDER BY cargoNivel, funcSexo\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------+------------------+\n",
            "|cargoNivel|funcSexo|Média dos Salários|\n",
            "+----------+--------+------------------+\n",
            "|    JUNIOR|       F|           2440.23|\n",
            "|    JUNIOR|       M|           2437.86|\n",
            "|     PLENO|       F|           7641.94|\n",
            "|     PLENO|       M|           6259.61|\n",
            "|    SENIOR|       F|          12994.19|\n",
            "|    SENIOR|       M|           14480.5|\n",
            "+----------+--------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "varyr5djDP2s"
      },
      "source": [
        "## 6.2 Consulta 2\n",
        "\n",
        "Qual o total de gastos em salários considerando os estados nos quais as equipes estão localizadas no trimestre 3 do ano de 2020? \n",
        "\n",
        "Para se realizar esta consulta, é necessário obter dados das tabelas de dimensão `equipe` e `data`, bem como da tabela de fatos `pagamento`. A junção estrela deve ocorrer considerando as seguintes integridades referenciais:\n",
        "- `pagamento.dataPK = data.dataPK`\n",
        "- `pagamento.equipePK = equipe.equipePK`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSgE7xtPkGYf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "557a0462-0317-4683-a99f-87d6cb721834"
      },
      "source": [
        "query = \"\"\"\n",
        "SELECT filialEstadoNome, ROUND(SUM(salario),2) AS Total\n",
        "FROM pagamento JOIN data ON data.dataPK = pagamento.dataPK \n",
        "               JOIN equipe ON equipe.equipePK = pagamento.equipePK\n",
        "WHERE dataAno = 2019\n",
        "      AND dataTrimestre = 3\n",
        "GROUP BY filialEstadoNome\n",
        "ORDER BY Total \n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+----------+\n",
            "|  filialEstadoNome|     Total|\n",
            "+------------------+----------+\n",
            "|        PERNAMBUCO| 438121.26|\n",
            "|MATO GROSSO DO SUL|1013857.74|\n",
            "|    RIO DE JANEIRO|1258479.57|\n",
            "|         SAO PAULO|1931458.02|\n",
            "+------------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAqNkANBOZSI"
      },
      "source": [
        "## 6.3 Consulta 3\n",
        "\n",
        "Qual o custo/benefício das equipes quando analisado o semestre 1 do ano de 2020?\n",
        "\n",
        "A idea da consulta é relacionar os gastos em salários e os ganhos em receitas considerando cada equipe e o período especificado. Portanto, para se realizar essa consulta, é necessário obter dados das tabelas de dimensão `equipe` e `data`, bem como das tabelas de fatos `pagamento` e `negociacao`. \n",
        "\n",
        " A junção estrela deve ocorrer considerando as seguintes integridades referenciais:\n",
        "- `pagamento.dataPK = data.dataPK`\n",
        "- `pagamento.equipePK = equipe.equipe.PK`\n",
        "- `negociacao.dataPK = data.dataPK`\n",
        "- `negociacao.equipePK = equipe.equipe.PK`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMyeJDwisUgu"
      },
      "source": [
        "Uma observação muito importante refere-se ao fato que, para evitar dubiedade nas respostas, elas devem ser feitas sempre considerando a chave primária, desde que a chave primária identifica univocamente cada tupla. Depois de ser resolvida a consulta em termos da chave primária, então deve ser obtido os demais atributos a serem exibidos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MybQ9xten5-x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c2a4ecd-ef30-4f2c-f1b3-419b1458e3cc"
      },
      "source": [
        "query = \"\"\"\n",
        "-- obtendo os dados a serem exibidos na resposta\n",
        "SELECT equipeNome, filialNome, ROUND(Lucro,2)\n",
        "FROM equipe,\n",
        "(\n",
        "   SELECT pag.equipePK AS retornaEquipePK, (TotalReceita - TotalSalario) AS Lucro\n",
        "   FROM ( \n",
        "        -- investigando os gastos em salarios de cada equipe no último semestre deste ano \n",
        "        SELECT equipePK, SUM(salario) AS TotalSalario\n",
        "        FROM pagamento JOIN data ON data.dataPK = pagamento.dataPK\n",
        "        WHERE dataSemestre = 1 \n",
        "              AND dataAno = 2020\n",
        "        GROUP BY equipePK \n",
        "        ORDER BY equipePK \n",
        "        ) AS pag,  \n",
        "        (\n",
        "        -- investigando os ganhos em receitas de cada equipe no último semestre deste ano   \n",
        "        SELECT equipePK, SUM(receita) AS TotalReceita\n",
        "        FROM negociacao JOIN data ON data.dataPK = negociacao.dataPK\n",
        "        WHERE dataSemestre = 1 \n",
        "              AND dataAno = 2020\n",
        "        GROUP BY equipePK \n",
        "        ORDER BY equipePK\n",
        "        ) AS neg\n",
        "   WHERE pag.equipePK = neg.equipePK\n",
        "   ) AS parte\n",
        "WHERE equipe.equipePK = parte.retornaEquipePK\n",
        "ORDER BY Lucro DESC\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show(5)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+--------------------+---------------+\n",
            "|    equipeNome|          filialNome|round(Lucro, 2)|\n",
            "+--------------+--------------------+---------------+\n",
            "|BI & ANALYTICS|SAO PAULO - AV. P...|     4054890.24|\n",
            "|BI & ANALYTICS|     RECIFE - CENTRO|     3788503.18|\n",
            "| APP - DESKTOP|RIO DE JANEIRO - ...|      278013.26|\n",
            "|  APP - MOBILE|SAO PAULO - AV. P...|      151160.49|\n",
            "| APP - DESKTOP|SAO PAULO - AV. P...|       99579.85|\n",
            "+--------------+--------------------+---------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHDrhy6xkTyO"
      },
      "source": [
        "## 6.4 Exercícios Essenciais"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeKcM4Ctkhv1"
      },
      "source": [
        "### **EXERCÍCIO 5 (Essencial)**\n",
        "\n",
        "Qual é a quantidade de negociações realizadas por ano e semestre? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsYBeatLXthq",
        "outputId": "965c865c-a2c0-437e-dac4-60c3f988beac"
      },
      "source": [
        "negociacao.columns"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['equipePK', 'clientePK', 'dataPK', 'receita', 'quantidadeNegociacoes']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYuxHCDChlsR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d22f10e-88c6-4bc4-aa46-8e81e68df635"
      },
      "source": [
        "# Resposta do exercício\n",
        "query = \"\"\"\n",
        "SELECT dataAno, dataSemestre, CAST(SUM(quantidadeNegociacoes) AS INTEGER) AS `Quantidade de Negociações`\n",
        "FROM data JOIN negociacao ON (data.dataPK = negociacao.dataPK)\n",
        "GROUP BY dataano, datasemestre\n",
        "ORDER BY dataano, datasemestre\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+-------------------------+\n",
            "|dataAno|dataSemestre|Quantidade de Negociações|\n",
            "+-------+------------+-------------------------+\n",
            "|   2016|           1|                      137|\n",
            "|   2016|           2|                      134|\n",
            "|   2017|           1|                      256|\n",
            "|   2017|           2|                      281|\n",
            "|   2018|           1|                      457|\n",
            "|   2018|           2|                      392|\n",
            "|   2019|           1|                      619|\n",
            "|   2019|           2|                      603|\n",
            "|   2020|           1|                      573|\n",
            "|   2020|           2|                      559|\n",
            "+-------+------------+-------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caBW3L8jkuhN"
      },
      "source": [
        "### **EXERCÍCIO 6 (Essencial)**\n",
        "\n",
        "Compare a quantidade de negociações que cada uma das equipes realizou nos anos de 2018 e 2019. \n",
        "\n",
        "Considere relacionar as equipes por meio da operação *drill-across*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lByxDksYh6aM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db714d0d-7576-4c14-dcea-3e918ea2e831"
      },
      "source": [
        "# Resposta do exercício\n",
        "query = \"\"\"\n",
        "SELECT negoc_2018.equipenome, negoc_2018.filialnome, negoc_2018.negociacoes_2018, negoc_2019.negociacoes_2019\n",
        "FROM ( -- cálculo para o ano de 2018\n",
        "      SELECT equipe.equipenome, equipe.filialnome, SUM(negociacao.quantidadenegociacoes) AS negociacoes_2018\n",
        "      FROM data JOIN negociacao ON (data.datapk = negociacao.datapk)\n",
        "                JOIN equipe ON (equipe.equipepk = negociacao.equipepk)\n",
        "      WHERE data.dataano = 2018\n",
        "      GROUP BY equipe.equipenome, equipe.filialnome\n",
        "      ) AS negoc_2018\n",
        "      JOIN ( -- -- cálculo para o ano de 2019\n",
        "      SELECT equipe.equipenome, equipe.filialnome, SUM(negociacao.quantidadenegociacoes) AS negociacoes_2019\n",
        "      FROM data JOIN negociacao ON (data.datapk = negociacao.datapk)\n",
        "                JOIN equipe ON (equipe.equipepk = negociacao.equipepk)\n",
        "      WHERE data.dataano = 2019\n",
        "      GROUP BY equipe.equipenome, equipe.filialnome\n",
        "      ) AS negoc_2019\n",
        "      ON (negoc_2018.equipenome = negoc_2019.equipenome AND negoc_2018.filialnome = negoc_2019.filialnome) -- união dos dois anos\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+--------------------+----------------+----------------+\n",
            "|   equipenome|          filialnome|negociacoes_2018|negociacoes_2019|\n",
            "+-------------+--------------------+----------------+----------------+\n",
            "|          WEB|CAMPO GRANDE - CE...|           100.0|            95.0|\n",
            "| APP - MOBILE|SAO PAULO - AV. P...|           104.0|           108.0|\n",
            "|APP - DESKTOP|RIO DE JANEIRO - ...|           149.0|           135.0|\n",
            "| APP - MOBILE|RIO DE JANEIRO - ...|            99.0|           112.0|\n",
            "| APP - MOBILE|CAMPO GRANDE - CE...|            98.0|            88.0|\n",
            "|          WEB|RIO DE JANEIRO - ...|            91.0|           106.0|\n",
            "|APP - DESKTOP|SAO PAULO - AV. P...|           132.0|           135.0|\n",
            "|          WEB|SAO PAULO - AV. P...|            76.0|            87.0|\n",
            "+-------------+--------------------+----------------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4MWxn4ak3R7"
      },
      "source": [
        "### **EXERCÍCIO 7 (Essencial)**\n",
        "Qual a quantidade de negociações realizadas pelos clientes residentes no estado de Pernambuco, por ano?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8PAkBpKiLxx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "939690ee-a973-4bb4-c5e9-a9154eaa7ae8"
      },
      "source": [
        "# Resposta do exercício\n",
        "query = \"\"\"\n",
        "SELECT dataAno, CAST(SUM(quantidadeNegociacoes) AS INTEGER) AS `Quantidade de Negociações`\n",
        "FROM negociacao JOIN data ON (negociacao.datapk = data.datapk)\n",
        "                JOIN cliente ON (negociacao.clientepk = cliente.clientepk)\n",
        "WHERE cliente.clienteestadosigla = 'PE'\n",
        "GROUP BY dataano\n",
        "ORDER BY dataano\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------------------------+\n",
            "|dataAno|Quantidade de Negociações|\n",
            "+-------+-------------------------+\n",
            "|   2016|                       26|\n",
            "|   2017|                       48|\n",
            "|   2018|                       46|\n",
            "|   2019|                       72|\n",
            "|   2020|                       63|\n",
            "+-------+-------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HpvYqBcvDS0"
      },
      "source": [
        "## 6.5 Exercícios Complementares"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZH5DoDr5jZT"
      },
      "source": [
        "Os exercícios a seguir devem ser implementados em ordem, ou seja, a resposta do exercício depende da resposta do exercício anterior, se esse existir. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jN4Ss3OWvWQT"
      },
      "source": [
        "### **EXERCÍCIO 8 (Complementar)**\n",
        "\n",
        "Qual o total de receita gerada no último semestre de 2020 (ou seja, semestre 2 do ano de 2020), considerando cada setor de clientes? Ordene o resultado final pelo total de receita em ordem ascendente. Renomeie o total de receitas como \"Total de Receitas\". "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Boxgnt9qwE5E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e9c5ca0-9c7d-4dd2-dee3-fea3ed5415d4"
      },
      "source": [
        "# Resposta do exercício\n",
        "\n",
        "query = \"\"\"\n",
        "SELECT clienteSetor, ROUND(SUM(receita), 2) As `Total de Receitas`\n",
        "FROM negociacao JOIN data ON data.dataPK = negociacao.dataPK\n",
        "                JOIN cliente ON cliente.clientePK = negociacao.clientePK\n",
        "WHERE dataAno = 2020 AND dataSemestre = 2\n",
        "GROUP BY clienteSetor\n",
        "ORDER BY SUM(receita) \n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-----------------+\n",
            "|       clienteSetor|Total de Receitas|\n",
            "+-------------------+-----------------+\n",
            "|            CREDITO|         998789.6|\n",
            "|          VESTUARIO|        2336266.5|\n",
            "|         TECNOLOGIA|       2465926.05|\n",
            "|              SAUDE|        3119775.3|\n",
            "|BEBIDAS E ALIMENTOS|        5749704.7|\n",
            "+-------------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Itsh4D7xJxQ"
      },
      "source": [
        "### **EXERCÍCIO 9 (Complementar)** \n",
        "\n",
        "No exercício anterior, foi calculado o total de receita gerada no último semestre de 2020 (ou seja, semestre 2 do ano de 2020) para cada setor de atuação dos clientes. Analisando-se os resultados obtidos, é possível identificar o setor de maior receita. Utilizando esse setor, responda à seguinte consulta analítica. \n",
        "\n",
        "Qual o total de receita gerada por mês para o setor de clientes com maior receita no último semestre de 2020 (ou seja, semestre 2 do ano de 2020)? Ordene o resultado final por mês em ordem ascendente. Renomeie o total de receitas como \"Total de Receitas\". "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57lxJu_5xWRx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f1d5f11-f826-43b1-aef4-42cb3cb47699"
      },
      "source": [
        "# Resposta do exercício\n",
        "# Setor de maior receita: Bebidas e Alimentos\n",
        "\n",
        "query = \"\"\"\n",
        "SELECT dataMes, ROUND(SUM(receita), 2) AS `Total de Receitas`\n",
        "FROM negociacao JOIN data ON data.dataPK = negociacao.dataPK \n",
        "                JOIN cliente ON cliente.clientePK = negociacao.clientePK \n",
        "WHERE dataAno = 2020 \n",
        "      AND dataSemestre = 2 \n",
        "      AND clienteSetor = 'BEBIDAS E ALIMENTOS' \n",
        "GROUP BY dataMes \n",
        "ORDER BY CAST(dataMes AS INTEGER)\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------+\n",
            "|dataMes|Total de Receitas|\n",
            "+-------+-----------------+\n",
            "|      7|        849631.35|\n",
            "|      8|         875934.3|\n",
            "|      9|        877223.55|\n",
            "|     10|        1091389.5|\n",
            "|     11|        1156403.3|\n",
            "|     12|         899122.7|\n",
            "+-------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfI-JNP_ysxy"
      },
      "source": [
        "### **EXERCÍCIO 10 (Complementar)** \n",
        "\n",
        "No exercício anterior, foi calculado o total de receita gerada por mês para o setor de clientes com maior receita no último semestre de 2020 (ou seja, semestre 2 do ano de 2020). Analisando-se os resultados obtidos, é possível identificar o mês de maior receita. Utilizando esse mês, responda à seguinte consulta analítica.\n",
        "\n",
        "Qual equipe gerou mais receita para o mês de maior receita da consulta analítica anterior? Renomeie o total de receitas como \"Total de Receitas\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXl88MHDy5vE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24614ae2-55d9-42dd-fefb-e200f6db1f90"
      },
      "source": [
        "# Resposta do exercício\n",
        "# Mês de maior receita: 11\n",
        "\n",
        "query = \"\"\"\n",
        "SELECT equipeNome, filialNome, ROUND(SUM(receita), 2) AS `Total de Receitas`\n",
        "FROM negociacao JOIN data ON data.dataPK = negociacao.dataPK \n",
        "                JOIN cliente ON cliente.clientePK = negociacao.clientePK\n",
        "                JOIN equipe ON equipe.equipePK = negociacao.equipePK \n",
        "WHERE dataAno = 2020 \n",
        "      AND dataMes = 11 \n",
        "      AND clienteSetor = 'BEBIDAS E ALIMENTOS' \n",
        "GROUP BY equipeNome, filialNome \n",
        "ORDER BY SUM(receita)\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+--------------------+-----------------+\n",
            "|    equipeNome|          filialNome|Total de Receitas|\n",
            "+--------------+--------------------+-----------------+\n",
            "|           WEB|CAMPO GRANDE - CE...|         20042.75|\n",
            "|  APP - MOBILE|SAO PAULO - AV. P...|         26571.85|\n",
            "| APP - DESKTOP|RIO DE JANEIRO - ...|         35645.65|\n",
            "|  APP - MOBILE|CAMPO GRANDE - CE...|         48714.45|\n",
            "|  APP - MOBILE|RIO DE JANEIRO - ...|          62138.7|\n",
            "|           WEB|RIO DE JANEIRO - ...|          68596.1|\n",
            "|           WEB|SAO PAULO - AV. P...|          88624.5|\n",
            "| APP - DESKTOP|SAO PAULO - AV. P...|         129409.4|\n",
            "|BI & ANALYTICS|SAO PAULO - AV. P...|        149490.15|\n",
            "|BI & ANALYTICS|     RECIFE - CENTRO|        527169.75|\n",
            "+--------------+--------------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DHcWDyVjm6g"
      },
      "source": [
        "### **AVALIAÇÃO SEMANAL 7 (Questão 4)** \n",
        "\n",
        "Considerando a constelação de fatos da BI Solutions, assinale a **alternativa** que corresponde à consulta SQL para: “Qual a quantidade de funcionários que tiveram salários lançados em outubro de 2020, por sexo? Ordene o resultado final pela quantidade de lançamentos”"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7_XOveoj6Ut",
        "outputId": "286999de-3f7b-4868-ca13-59a11911b123"
      },
      "source": [
        "query = \"\"\"\n",
        "SELECT funcSexo, SUM(quantidadeLancamentos)\n",
        "FROM funcionario JOIN pagamento ON funcionario.funcPK = pagamento.funcPK\n",
        "JOIN data ON data.dataPK = pagamento.dataPK\n",
        "WHERE dataMes = 10 AND dataAno = 2020\n",
        "GROUP BY funcSexo\n",
        "ORDER BY SUM(quantidadeLancamentos)\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------------------------------------------+\n",
            "|funcSexo|sum(CAST(quantidadeLancamentos AS DOUBLE))|\n",
            "+--------+------------------------------------------+\n",
            "|       F|                                      52.0|\n",
            "|       M|                                     148.0|\n",
            "+--------+------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8Wv9PCQkbet"
      },
      "source": [
        "### **AVALIAÇÃO SEMANAL 7 (Questão 5)** \n",
        "\n",
        "Considerando a constelação de fatos da BI Solutions, assinale a **alternativa** que corresponde à consulta SQL para: “Qual a média de salários no ano de 2020, considerando cada cargo e seus respectivos níveis? Ordene o resultado final pela média de salários, da maior média para a menor média.”"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GZlrd10kmjV",
        "outputId": "5196bae8-0f30-4aa4-9f3f-54faaed33839"
      },
      "source": [
        "query = \"\"\"\n",
        "SELECT cargoNome, cargoNivel, AVG(salario)\n",
        "FROM cargo JOIN pagamento ON cargo.cargoPK = pagamento.cargoPK\n",
        "JOIN data ON data.dataPK = pagamento.dataPK\n",
        "WHERE dataAno = 2020\n",
        "GROUP BY cargoNome, cargoNivel\n",
        "ORDER BY AVG(salario) DESC\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------+----------------------------+\n",
            "|           cargoNome|cargoNivel|avg(CAST(salario AS DOUBLE))|\n",
            "+--------------------+----------+----------------------------+\n",
            "|PROGRAMADOR DE AP...|    SENIOR|          29583.956666666683|\n",
            "|                 DBA|    SENIOR|           17310.42000000001|\n",
            "|ADMINISTRADOR DE ...|    SENIOR|                    16790.96|\n",
            "|    ANALISTA DE REDE|    SENIOR|          16233.242000000004|\n",
            "|PROGRAMADOR DE SI...|    SENIOR|          15566.433999999997|\n",
            "| ENGENHEIRO DE DADOS|    SENIOR|                   15335.505|\n",
            "|OPERADOR DE CENTR...|    SENIOR|          13929.913333333332|\n",
            "|ANALISTA DE SISTE...|    SENIOR|          13471.679999999995|\n",
            "|   DESIGNER DE GAMES|    SENIOR|          13408.614999999996|\n",
            "|CIENTISTA DE DADO...|    SENIOR|                     13351.0|\n",
            "|ANALISTA DE SUPOR...|    SENIOR|          11976.736000000006|\n",
            "|PROGRAMADOR FRONT...|    SENIOR|          11955.574999999997|\n",
            "|ADMINISTRADOR EM ...|    SENIOR|          11944.639999999989|\n",
            "|PROGRAMADOR DE SI...|    SENIOR|          11800.702500000007|\n",
            "|ANALISTA DE SUPOR...|    SENIOR|          11427.755000000003|\n",
            "|ADMINISTRADOR DE ...|     PLENO|                    10931.47|\n",
            "|ANALISTA DE SISTE...|    SENIOR|          10260.880000000001|\n",
            "|PROGRAMADOR DE AP...|     PLENO|                     8647.36|\n",
            "|PROGRAMADOR DE SI...|     PLENO|           7993.484285714289|\n",
            "|ANALISTA DE SISTE...|     PLENO|           7646.069999999997|\n",
            "+--------------------+----------+----------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwBuWqmOm7M0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}